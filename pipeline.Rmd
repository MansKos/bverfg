---
title: "Compilation Report | Corpus der Entscheidungen des Bundesverfassungsgerichts (CE-BVerfG)"
author: Seán Fobbe
geometry: margin=3cm
fontsize: 11pt
papersize: a4
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: tex/Preamble_DE.tex
      before_body: [temp/Definitions.tex, tex/Titlepage_Compilation.tex]
bibliography: temp/packages.bib
nocite: '@*'
---



```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = TRUE,
                      message = TRUE,
                      collapse = TRUE,
                      comment = "#>")
```




```{r, results = "asis", echo = FALSE}
cat(readLines("README.md"),
    sep = "\n")
```



# Packages laden


```{r}

library(targets)
library(tarchetypes)
library(RcppTOML)
library(future)
library(data.table)
library(quanteda)
library(knitr)
library(kableExtra)
library(igraph)
library(ggraph)

tar_unscript()
```



# Vorbereitung

## Definitionen

```{r}

## Datum
datestamp <- Sys.Date()
print(datestamp)

## Datum und Uhrzeit (Beginn)
begin.script <- Sys.time()

## Konfiguration
config <- RcppTOML::parseTOML("config.toml")
print(config)


# Analyse-Ordner
dir.analysis <- paste0(getwd(),
                       "/analysis")


```


## Aufräumen

Löscht Dateien im Output-Ordner, die nicht vom heutigen Tag sind.


```{r}

unlink(grep(datestamp,
            list.files("output",
                       full.names = TRUE),
            invert = TRUE,
            value = TRUE))


```



## Ordner erstellen

```{r}

#unlink("output", recursive = TRUE)
dir.create("output", showWarnings = FALSE)
dir.create("temp", showWarnings = FALSE)

dir.create(dir.analysis, showWarnings = FALSE)

```



## Vollzitate statistischer Software schreiben

```{r}
knitr::write_bib(renv::dependencies()$Package,
                 "temp/packages.bib")
```




# Globale Variablen


## Packages definieren

```{targets global-packages, tar_globals = TRUE}

tar_option_set(packages = c("tarchetypes",
                            "RcppTOML",     # TOML-Dateien lesen und schreiben
							"testthat",     # Unit Tests
                            "fs",           # Verbessertes File Handling
                            "zip",          # Verbessertes ZIP Handling
                            "mgsub",        # Vektorisiertes Gsub
                            "httr",         # HTTP-Werkzeuge
                            "rvest",        # HTML/XML-Extraktion
                            "knitr",        # Professionelles Reporting
                            "kableExtra",   # Verbesserte Kable Tabellen
                            "pdftools",     # Verarbeitung von PDF-Dateien
                            "ggplot2",      # Datenvisualisierung
							"ggraph",       # Visualisierung von Graphen
                            "scales",       # Skalierung von Diagrammen
                            "data.table",   # Fortgeschrittene Datenverarbeitung
                            "readtext",     # TXT-Dateien einlesen
							"udpip",        # Annotation von Texten
                            "quanteda",     # Computerlinguistik
                            "future",       # Parallelisierung
                            "future.apply"))# Funktionen für Future

tar_option_set(workspace_on_error = TRUE) # Save Workspace on Error
tar_option_set(format = "qs")

```


## Konfiguration


```{targets global-config, tar_globals = TRUE}

datestamp <- Sys.Date()

config <- RcppTOML::parseTOML("config.toml")

dir.analysis <- paste0(getwd(),
                       "/analysis")

## Caption for diagrams
caption <- paste("Fobbe | DOI:",
                 config$doi$data$version)


## Prefix for figure titles
prefix.figuretitle <- paste(config$project$shortname,
                            "| Version",
                            datestamp)

## File prefix
prefix.files <- paste0(config$project$shortname,
                       "_",
                       datestamp)


if (config$cores$max == TRUE){
    fullCores <- future::availableCores() - 1
}


if (config$cores$max == FALSE){
    fullCores <- as.integer(config$cores$number)
}

```




## Funktionen definieren

```{targets global-functions, tar_globals = TRUE}

lapply(list.files("functions", pattern = "\\.R$", full.names = TRUE), source)

```



## Metadaten für TXT-Dateien definieren

```{targets global-txtvars, tar_globals = TRUE}

docvarnames <- c("gericht",
                 "datum",
                 "spruchkoerper_typ",
                 "spruchkoerper_az",
                 "registerzeichen",
                 "eingangsnummer",
                 "eingangsjahr_az",
                 "kollision",
                 "name",
                 "band",
                 "seite")

```


## ZIP-Datei für Source definieren

```{targets global-sourcefiles, tar_globals = TRUE}

files.source.raw <-  c(list.files(pattern = "\\.R$|\\.toml$|\\.md$|\\.Rmd$"),
					   "reports",
                       "data",
                       "functions",
                       "tex",
                       "gpg",
                       "buttons",
                       list.files(pattern = "renv\\.lock|\\.Rprofile",
                                  all.files = TRUE),
                       list.files("renv",
                                  pattern = "activate\\.R",
                                  full.names = TRUE))

```






# Pipeline: Konstruktion




## File Tracking Targets

Mit diesem Abschnitt der Pipeline werden Input-Dateien getrackt und eingelesen. Mit der Option \enquote{format = "file"} werden für Input-Dateien Prüfsummen berechnet. Falls sich diese verändern werden alle von ihnen abhängigen Pipeline-Schritte als veraltet markiert und neu berechnet.






### Source Code

Dies sind alle Dateien, die den Source Code für den Datensatz bereitstellen.

```{targets tar.file1}
tar_target(files.source,
           files.source.raw,
           format = "file")

```


### Changelog

```{targets tar.file2}
tar_target(changelog,
           "CHANGELOG.md",
           format = "file")
```



### Variablen für die BVerfGE

Diese Tabelle enthält Name, Band und Seite der Entscheidung in der BVerfGE. 


```{targets tar.file3}
list(
    tar_target(file.var_bverfge,
               "data/BVerfGE_Variablen_NameBandSeite.csv",
               format = "file"),
    tar_target(dt.var_bverfge,
               fread(file.var_bverfge))
)
```





### Liste aller Variablen

Die Variablen des Datensatzes, inklusive ihrer Erläuterung.


```{targets tar.file4}
list(
    tar_target(file.var_codebook,
               "data/CE-BVerfG_Variables.csv",
               format = "file"),
    tar_target(dt.var_codebook,
               fread(file.var_codebook))
)
```



### Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD)

Die Tabelle der Registerzeichen und der ihnen zugeordneten Verfahrensarten stammt aus dem folgenden Datensatz: \enquote{Seán Fobbe (2021). Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD). Version 1.0.1. Zenodo. DOI: 10.5281/zenodo.4569564.}

`

```{targets tar.file5}
list(
    tar_target(file.az.brd,
           "data/AZ-BRD_1-0-1_DE_Registerzeichen_Datensatz.csv",
           format = "file"),
     tar_target(az.brd,
                fread(file.az.brd))
     )
```

### Presidents and Vice-Presidents of the Federal Courts of Germany (PVP-FCG)

 Die Personendaten stammen aus folgendem Datensatz: \enquote{Seán Fobbe and Tilko Swalve (2021). Presidents and Vice-Presidents of the Federal Courts of Germany (PVP-FCG). Version 2021-04-08. Zenodo. DOI: 10.5281/zenodo.4568682}.


```{targets tar.file6}
list(
    tar_target(file.presidents,
           "data/PVP-FCG_2021-04-08_GermanFederalCourts_Presidents.csv",
           format = "file"),
     tar_target(presidents,
                fread(file.presidents))
     )
```



```{targets tar.file7}
list(
    tar_target(file.vpresidents,
           "data/PVP-FCG_2021-04-08_GermanFederalCourts_VicePresidents.csv",
           format = "file"),
     tar_target(vpresidents,
                fread(file.vpresidents))
     )
```






## Download Targets


### Vorläufige Download-Tabelle erstellen

```{targets tar.download1}
tar_target(dt.download,
           f.download_table_make(debug.toggle = config$debug$toggle,
                                 debug.pages = config$debug$pages))
```

### Vorläufige Dateinamen erstellen

```{targets tar.download2}
tar_target(filenames.raw,
           f.filenames_raw(url.pdf = dt.download$url_pdf))
```

### Finale Dateinamen erstellen

```{targets tar.download3}
tar_target(filenames.final,
           f.filenames_final(filenames.raw = filenames.raw,
                             var.bverfge = dt.var_bverfge))
```


### Finale Download-Tabelle erstellen

```{targets tar.download4}
tar_target(dt.download.final,
           data.table(dt.download,
                      doc_id = filenames.final))
```


### Download durchführen (PDF)


```{targets tar.download5}
tar_target(files.pdf,
                f.download(url = dt.download.final$url_pdf,
                           filename = dt.download.final$doc_id,
                           dir = "pdf",
                           sleep.min = 0.3,
                           sleep.max = 1,
                           retries = 3,
                           retry.sleep.min = 2,
                           retry.sleep.max = 5,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```


### Download durchführen (HTML)


```{targets tar.download6}
tar_target(files.html,
                f.download(url = dt.download.final$url_html,
                           filename = basename(dt.download.final$url_html),
                           dir = "html",
                           sleep.min = 0,
                           sleep.max = 0.2,
                           retries = 3,
                           retry.sleep.min = 2,
                           retry.sleep.max = 5,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```



## Convert Targets


### TXT-Dateien erstellen und einlesen

Es werden die PDF-Dateien in TXT konvertiert und mitsamt den Variablen in ihren Dateinamen eingelesen. Beim Einlesen werden die in PDF-Dateien üblichen über Zeilen gebrochene Wörter wieder zusammengefügt.



```{targets tar.convert1}

list(tar_target(files.txt,
                f.tar_pdf_extract(x = files.pdf,
                                  outputdir = "txt",
								  multicore = config$parallel$extractPDF,
                                  cores = fullCores),
                format = "file"),
     tar_target(dt.bverfg,
                f.readtext(x = files.txt,
                           docvarnames = docvarnames))
     )
					
```					


### HTML-Dateien parsen

```{targets tar.convert2}

tar_target(html.parsed,
           f.parse_html_bverfg(html = files.html))

```


### HTML Parse-Ergebnis splitten



```{targets tar.convert3}

list(
    tar_target(dt.html.meta,
               f.clean_meta(html.parsed$dt.meta.html)),
    tar_target(dt.segmented,
               f.clean_segmented(html.parsed$dt.segmented.full))
)
		   

```





## Enhance Targets

Dieser Abschnitt der Pipeline berechnet diverse Verbesserungen für den Datensatz und führt diese am Ende zusammen.


### Daten standardisieren

Das Datum wird im ISO-Format standardisiert und die Variablen \enquote{entscheidungsjahr} und \enquote{eingangsjahr\_iso} hinzugefügt.


```{targets tar.enhance1}
tar_target(dt.bverfg.datecleaned,
           f.clean_dates(dt.bverfg))
```



### Variable erstellen: \enquote{verfahrensart}

Die Variable \enquote{verfahrensart} wird aus den Registerzeichen berechnet.

```{targets tar.enhance2}
tar_target(var_verfahrensart,
                f.var_verfahrensart(dt.bverfg.datecleaned$registerzeichen,
                                    az.brd = az.brd,
                                    gericht = "BVerfG"))
```


### Variable erstellen: \enquote{aktenzeichen}

Das Aktenzeichen wird aus seinen Komponenten berechnet.


```{targets tar.enhance3}
tar_target(var_aktenzeichen,
                f.var_aktenzeichen(dt.bverfg.datecleaned,
                                   az.brd = az.brd,
                                   gericht = "BVerfG",
								   remove.na = TRUE))
```


### Variable erstellen: \enquote{ecli}

Die ECLI wird aus ihren Komponenten berechnet.



```{targets tar.enhance4}
tar_target(var_ecli,
           f.var_ecli_bverfg(x = dt.bverfg.datecleaned))
```




### Variable erstellen: \enquote{praesi}


```{targets tar.enhance5}
tar_target(var_praesi,
           f.presidents(datum = dt.bverfg.datecleaned$datum,
                        gericht = "BVerfG",
						pvp.fcg = presidents))
```

### Variable erstellen: \enquote{vpraesi}


```{targets tar.enhance6}
tar_target(var_vpraesi,
           f.presidents(datum = dt.bverfg.datecleaned$datum,
                        gericht = "BVerfG",
						pvp.fcg = vpresidents))
```




### Variablen erstellen: \enquote{zeichen, token, typen, saetze}

Berechnung klassischer linguistischer Kennzahlen.



```{targets tar.enhance8}
tar_target(var_lingstats,
                f.lingstats(dt.bverfg.datecleaned,
                            multicore = config$parallel$lingsummarize,
                            cores = fullCores,
                            germanvars = TRUE))
```





### Konstanten erstellen

Konstanten die dem Datensatz wichtige Herkunftsinformationen hinzufügen. Darunter sind die Versionsnummer, die Version DOI, die Concept DOI und die Lizenz.



```{targets tar.enhance9}
tar_target(var_constants,
           data.frame(version = as.character(datestamp),
                      doi_concept = config$doi$data$concept,
                      doi_version = config$doi$data$version,
                      lizenz = as.character(config$license$data))[rep(1,
                                                                      nrow(dt.bverfg.datecleaned)),])
```





### Zusätzliche Variablen zusammenführen

```{targets tar.enhance10}
tar_target(vars_additional,
           data.table(verfahrensart = var_verfahrensart,
                      aktenzeichen = var_aktenzeichen,
                      ecli = var_ecli,
                      praesi = var_praesi,
                      v_praesi = var_vpraesi,
                      var_lingstats,
                      var_constants))

```


### Datensatz und zusätzliche Variablen verbinden

```{targets tar.enhance11}
tar_target(dt.bverfg.intermediate,
           cbind(dt.bverfg.datecleaned,
                 vars_additional))

```

### Hauptdatensatz in segmentierte Variante mergen

```{targets tar.enhance12}

tar_target(dt.segmented.final,
           merge(dt.segmented,
                 dt.bverfg.intermediate[,!"text"],
                 by = "ecli",
                 all.x = TRUE,
                 sort = FALSE))
				 
```


### Finalen Datensatz erstellen

Die Verbesserungen der vorherigen Schritte werden in dieser Funktion zusammengefügt um den finalen Datenatz herzustellen.


```{targets tar.enhance13}
tar_target(dt.bverfg.final,
           f.finalize(x = dt.bverfg.intermediate,
                      download.table = dt.download.final,
                      html.meta = dt.html.meta,
                      varnames = dt.var_codebook$varname))

```



### Variante erstellen: Nur Metadaten

Hier wird die Text-Variable entfernt, um eine deutlich platzsparendere Variante des Datensatzes zu erstellen. Enthalten sind nur noch die Metadaten.



```{targets tar.enhance14}
tar_target(dt.bverfg.meta,
                dt.bverfg.final[, !"text"])

```


### Variante erstellen: Annotiert


```{targets tar.enhance15}
tar_target(dt.bverfg.annotated,
           f.tar_udpipe(dt.bverfg.final,
                        language = "german-hdt",
                        model_dir = "temp",
                        cores = fullCores))

```







## Write Targets

Dieser Abschnitt der Pipeline schreibt den Datensatz und alle Hash-Prüfsummen auf die Festplatte.



### CSV schreiben: Voller Datensatz

```{targets tar.write1}
tar_target(csv.final,
           f.tar_fwrite(x = dt.bverfg.final,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_DE_CSV_Datensatz.csv"))
                        )
           )
```



### CSV schreiben: Metadaten


```{targets tar.write2}
tar_target(csv.meta,
           f.tar_fwrite(x = dt.bverfg.meta,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_DE_CSV_Metadaten.csv"))
                        )
           )
```







## Report Targets

Dieser Abschnitt der Pipeline erstellt die finalen Berichte (Codebook und Robustness Checks).



### LaTeX-Definitionen schreiben

Um Variablen aus der Pipeline in die LaTeX-Kompilierung einzuführen, müssen diese als .tex-Datei auf die Festplatte geschrieben werden.

```{targets tar.report1}
tar_target(latexdefs,
                f.latexdefs(config,
                            dir = "temp",
                            version = datestamp),
	       format = "file")

```



### Zusammenfassungen linguistischer Kennwerte berechnen

```{targets tar.report2}
tar_target(lingstats.summary,
                f.lingstats_summary(dt.bverfg.final,
                                    germanvars = TRUE))

```






# Pipeline: Kompilierung



## Durchführen der Kompilierung

```{r pipeline-run, results = "hide"}
tar_make()
```



## Visualisierung

```{r, pipeline-graph, fig.width = 12, fig.height = 12}

edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)


ggraph(g,
       'sugiyama') + 
    geom_edge_diagonal(colour = "grey")+
    geom_node_point()+
    geom_node_text(aes(label = name),
                   size = 2,
                   repel = TRUE)+
    theme_void()

```
                       



# Pipeline: Analyse


## Gesamte Liste

Die vollständige Liste aller Targets, inklusive ihres Types und ihrer Größe. Targets die auf Dateien verweisen (z.B. alle PDF-Dateien) geben die Gesamtgröße der Dateien auf der Festplatte an.





```{r, pipeline-list}

meta <- tar_meta(fields = c("type", "bytes"), complete_only = TRUE)
setDT(meta)
meta$MB <- round(meta$bytes / 1e6, digits = 2)

# Gesamter Speicherplatzverbrauch
sum(meta$MB, na.rm = TRUE)

kable(meta[order(type, name)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```

\newpage
## Timing

### Gesamte Laufzeit

```{r, pipeline-runtime}
meta <- tar_meta(fields = c("time", "seconds"), complete_only = TRUE)
setDT(meta)
meta$mins <- round(meta$seconds / 60, digits = 2)

runtime.sum <- sum(meta$seconds)

## Sekunden
print(runtime.sum)

## Minuten
runtime.sum / 60

## Stunden
runtime.sum / 3600
```

### Laufzeit einzelner Targets

Der Zeitpunkt an dem die Targets berechnet wurden und ihre jeweilige Laufzeit in Sekunden.


```{r, pipeline-timing}
kable(meta[order(-seconds)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```



\newpage
## Warnungen


```{r, pipeling-warnings}

meta <- tar_meta(fields = "warnings", complete_only = TRUE)
setDT(meta)

kable(meta,
      format = "latex",
      align = c("P{4cm}", "p{10cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```


\newpage
## Fehlermeldungen

```{r, pipeline-errors}

meta <- tar_meta(fields = "error", complete_only = TRUE)
setDT(meta)

kable(meta,
      format = "latex",
      align = c("P{4cm}", "p{10cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```







\newpage

```{r, results = "asis", echo = FALSE}
cat(readLines("CHANGELOG.md"),
    sep = "\n")

```


# Abschluss

```{r}

## Datumsstempel
print(datestamp) 

## Datum und Uhrzeit (Anfang)
print(begin.script)


## Datum und Uhrzeit (Ende)
end.script <- Sys.time()
print(end.script)


## Laufzeit des gesamten Skriptes
print(end.script - begin.script)

```


# Parameter für strenge Replikationen


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Literaturverzeichnis
